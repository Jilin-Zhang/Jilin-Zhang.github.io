---
title: "ANVMP: A 28nm 52.6μW 1.25pJ/SOP Asynchronous Non-Volatile-Memory-based Computing-In-Memory Neuromorphic Processor for Edge-AI Applications"
collection: publications
permalink: /publication/ANVMP
excerpt: 'With the development of on-chip learning processors for edge-AI applications, energy efficiency of NN inference and training is more and more critical. As on-chip training energy dominates the energy consumption of edge-AI processors [1], [2], [4], [5], reduction is of paramount importance. Spiking neural networks (SNNs) offer energy-efficient inference and learning compared with convolutional neural networks (CNNs) or deepneural networks (DNNs), but SNN-based processors have three challenges that need to be addressed (Fig. 22.6.1). 1) During on-chip training, some factors involved in ΔW computation are zeros resulting in ΔW=O, leading to redundant ΔW computation and memory access for weight update. 2) After reaching a certain accuracy, more data cannot improve the accuracy significantly, and 95% of the energy is wasted on the unnecessary processing of the input spike events afterwards. 3) In the case of sparse input-spike events, the number of spike events in each time step is different. If spike processing is synchronized by time step, the worst-case scenario needs to be considered. As a result, energy and time are wasted.'
date: 2024-11-08
venue: 'ASSCC'
paperurl: '-'
citation: 'Jilin Zhang, Qiumeng Wei, Dexuan Huo, Tao Li, Bin Gao, He Qian, Huaqiang Wu, Kea-Tiong Tang, Hong Chen*, “ANVMP: A 28nm 52.6μW 1.25pJ/SOP Asynchronous Non-Volatile-Memory-based Computing-In-Memory Neuromorphic Processor for Edge-AI Applications” The IEEE Asian Solid-State Circuits Conference (A-SSCC), November 18 - 21, 2024, Hiroshima, Japan'
---
